{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64306a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "# import torch.nn as nn \n",
    "import time\n",
    "import math\n",
    "# import torch.nn.functional as F\n",
    "#from net import *\n",
    "#from utils import *\n",
    "#from tracker import *\n",
    "import onnx\n",
    "\n",
    "from main.paths import ROOT_PATH  # isort:skip\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import sys\n",
    "import cv2\n",
    "from loguru import logger\n",
    "\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "# import torch.nn as nn \n",
    "import time\n",
    "import math\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "from tracker import *\n",
    "from videoanalyst.config.config import cfg as root_cfg\n",
    "from videoanalyst.config.config import specify_task\n",
    "from videoanalyst.data import builder as dataloader_builder\n",
    "from videoanalyst.engine import builder as engine_builder\n",
    "from videoanalyst.model import builder as model_builder\n",
    "from videoanalyst.optim import builder as optim_builder\n",
    "from videoanalyst.utils import Timer, complete_path_wt_root_in_cfg, ensure_dir\n",
    "from videoanalyst.pipeline import builder as pipeline_builder\n",
    "from videoanalyst.engine.builder import build as tester_builder\n",
    "from videoanalyst.engine.monitor.monitor_impl.tensorboard_logger import TensorboardLogger\n",
    "from videoanalyst.config.config import cfg as root_cfg\n",
    "from videoanalyst.config.config import specify_task\n",
    "from videoanalyst.engine.builder import build as tester_builder\n",
    "from videoanalyst.model import builder as model_builder\n",
    "from videoanalyst.pipeline import builder as pipeline_builder\n",
    "from videoanalyst.utils import complete_path_wt_root_in_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb00de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setNumThreads(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbe5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_args_config = '/home/meysam/test-apps/STMTrack/experiments/stmtrack/test/got10k/stmtrack-effnet-got.yaml'\n",
    "exp_cfg_path = osp.realpath(parsed_args_config)\n",
    "\n",
    "root_cfg.merge_from_file(exp_cfg_path)\n",
    "\n",
    "root_cfg = complete_path_wt_root_in_cfg(root_cfg, ROOT_PATH)\n",
    "\n",
    "task, task_cfg = specify_task(root_cfg.test)\n",
    "\n",
    "task_cfg.freeze()\n",
    "\n",
    "log_dir = osp.join(task_cfg.exp_save, task_cfg.exp_name, \"logs\")\n",
    "\n",
    "ensure_dir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e9d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 11:00:06.721 | INFO     | __main__:<module>:15 - Load experiment configuration at: /home/meysam/test-apps/STMTrack/experiments/stmtrack/test/got10k/stmtrack-effnet-got.yaml\n",
      "2024-08-26 11:00:06.722 | INFO     | __main__:<module>:16 - Merged with root_cfg imported from videoanalyst.config.config.cfg\n",
      "2024-08-26 11:00:06.740 | INFO     | __main__:<module>:23 - Task configuration backed up at /home/meysam/test-apps/STMTrack/logs/stmtrack-effnet-got-test/got10k/logs/got10k_bak.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.configure(\n",
    "        handlers=[\n",
    "            dict(sink=sys.stderr, level=\"INFO\"),\n",
    "            dict(sink=osp.join(log_dir, \"train_log.txt\"),\n",
    "                 enqueue=True,\n",
    "                 serialize=True,\n",
    "                 diagnose=True,\n",
    "                 backtrace=True,\n",
    "                 level=\"INFO\")\n",
    "        ],\n",
    "        extra={\"common_to_all\": \"default\"},\n",
    "    )\n",
    "\n",
    "# backup config\n",
    "logger.info(\"Load experiment configuration at: %s\" % exp_cfg_path)\n",
    "logger.info(\n",
    "    \"Merged with root_cfg imported from videoanalyst.config.config.cfg\")\n",
    "cfg_bak_file = osp.join(log_dir, \"%s_bak.yaml\" % task_cfg.exp_name)\n",
    "\n",
    "with open(cfg_bak_file, \"w\") as f:\n",
    "    f.write(task_cfg.dump())\n",
    "\n",
    "logger.info(\"Task configuration backed up at %s\" % cfg_bak_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "858f6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 11:00:07.585 | INFO     | videoanalyst.model.module_base:update_params:60 - Load pretrained STMTrack parameters from: /home/meysam/test-apps/STMTrack/snapshots/stmtrack-effnet-adam-got-train-val-mdim-16/epoch-10.pkl whose md5sum is eb75584f9834d555c7ef99dde0e7fe30\n"
     ]
    }
   ],
   "source": [
    "model = model_builder.build(task, task_cfg.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e309c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e6df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basemodel_Q(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Basemodel_Q, self).__init__()\n",
    "        self.backbone_q = model.basemodel_q\n",
    "        self.neck_q = model.neck_q\n",
    "    def forward(self, search_img):\n",
    "        fq = self.backbone_q(search_img)\n",
    "        fq = self.neck_q(fq)\n",
    "        return fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c80382",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Basemodel_Q()\n",
    "ONNX_FILE_PATH = \"onnx-files/mdim-16/backbone_q.onnx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8771e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(1,3,200,200).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "y = net(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985c2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(net, inp, ONNX_FILE_PATH, input_names=[\"search_img\"], output_names=[\"fq\"], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fa3c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Memorize(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Memorize, self).__init__()\n",
    "        self.backbone_m = model.basemodel_m\n",
    "        self.neck_m = model.neck_m\n",
    "    def forward(self, im_crop, fg_bg_label_map):\n",
    "        fm = self.backbone_m(im_crop, fg_bg_label_map)\n",
    "        fm = self.neck_m(fm)\n",
    "        fm = fm.permute(1, 0, 2, 3).unsqueeze(0).contiguous()  # B, C, T, H, W\n",
    "        return fm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2703e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Memorize()#(model.basemodel_m,model.neck_m)\n",
    "\n",
    "input = torch.ones(1,3,200,200).cuda()\n",
    "fg_bg = torch.ones(1,1,200,200).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "fm = net(input,fg_bg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "425402d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 1, 25, 25])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8af6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_FILE_PATH = \"onnx-files/mdim-16/memorize.onnx\"\n",
    "input = torch.randn(1,3,200,200).cuda()\n",
    "fg_bg = torch.randn(1,1,200,200).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "torch.onnx.export(net, (input,fg_bg), ONNX_FILE_PATH, input_names=[\"img\",\"fg_bg_label_map\"], output_names=[\"fm\"], export_params=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b15a182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = dict(\n",
    "        total_stride=8,\n",
    "        score_size=25,\n",
    "        score_offset=-1,\n",
    "        test_lr=0.95,\n",
    "        penalty_k=0.04,\n",
    "        window_influence=0.21,\n",
    "        windowing=\"cosine\",\n",
    "        m_size=200,\n",
    "        q_size=200,\n",
    "        min_w=10,\n",
    "        min_h=10,\n",
    "        phase_memorize=\"memorize\",\n",
    "        phase_track=\"track\",\n",
    "        corr_fea_output=False,\n",
    "        num_segments=4,\n",
    "        confidence_threshold=0.6,\n",
    "        gpu_memory_threshold=-1,\n",
    "        search_area_factor=4.0,\n",
    "        visualization=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48df3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(xy_ctr, offsets):\n",
    "    offsets = offsets.permute(0, 2, 3, 1)  # (B, H, W, C), C=4\n",
    "    offsets = offsets.reshape(offsets.shape[0], -1, 4)\n",
    "    xy0 = (xy_ctr[:, :, :] - offsets[:, :, :2])\n",
    "    xy1 = (xy_ctr[:, :, :] + offsets[:, :, 2:])\n",
    "    bboxes_pred = torch.cat([xy0, xy1], 2)\n",
    "\n",
    "    return bboxes_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "633eb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self,head):\n",
    "        super(Head, self).__init__()\n",
    "        self.head = head\n",
    "        self.total_stride = 8.0\n",
    "        score_offset = (hps[\"q_size\"] - 1.0 - (hps[\"score_size\"] - 1) * hps[\"total_stride\"]) // 2.0\n",
    "        self.fm_ctr = get_xy_ctr_np(hps[\"score_size\"], score_offset, hps[\"total_stride\"])\n",
    "    def forward(self,fm1,fm2,fm3,fm4,fm5,fm6,fq):\n",
    "\n",
    "        fm = torch.cat([fm1,fm2,fm3,fm4,fm5,fm6],dim = 2)\n",
    "        y = self.head.memory_read(fm, fq)\n",
    "        cls_score, ctr_score, offsets, cls_feat = self.head.solve(y)\n",
    "        \n",
    "        cls_score = cls_score.permute(0, 2, 3, 1)\n",
    "        cls_score = cls_score.reshape(cls_score.shape[0], -1, 1)\n",
    "\n",
    "        ctr_score = ctr_score.permute(0, 2, 3, 1)\n",
    "        ctr_score = ctr_score.reshape(ctr_score.shape[0], -1, 1)\n",
    "\n",
    "        offsets = torch.exp(self.head.si * offsets + self.head.bi) * 8.0\n",
    "\n",
    "        \n",
    "        fm_ctr = self.fm_ctr.to(offsets.device)\n",
    "        bbox = get_box(fm_ctr, offsets)\n",
    "        fcos_cls_score_final = cls_score\n",
    "        fcos_ctr_score_final = ctr_score\n",
    "        fcos_bbox_final = bbox\n",
    "\n",
    "        \n",
    "        fcos_cls_prob_final = torch.sigmoid(fcos_cls_score_final)\n",
    "        fcos_ctr_prob_final = torch.sigmoid(fcos_ctr_score_final)\n",
    "        # apply centerness correction\n",
    "        fcos_score_final = fcos_cls_prob_final * fcos_ctr_prob_final\n",
    "        return fcos_score_final, fcos_bbox_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "067b5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = Head(model.head)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "ONNX_FILE_PATH = \"onnx-files/mdim-16/head.onnx\"\n",
    "# fm = torch.randn(1, 512, 6, 25, 25).cuda()\n",
    "fm1 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm2 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm3 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm4 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm5 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm6 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "\n",
    "fq = torch.randn(1, 20, 25, 25).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5788a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c535ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae038eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b8a2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, bbox = net(fm1,fm2,fm3,fm4,fm5,fm6,fq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d393cbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meysam/test-apps/STMTrack/videoanalyst/model/task_head/taskhead_impl/stm_head.py:95: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  w = torch.bmm(fm, fq) / math.sqrt(C)  # B, THW, HW\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(net, (fm1,fm2,fm3,fm4,fm5,fm6,fq), \n",
    "                  ONNX_FILE_PATH, input_names=[\"fm1\",\"fm2\",\"fm3\",\"fm4\",\"fm5\",\"fm6\",\"fq\"], \n",
    "                  output_names=[\"score\", \"bbox\"]\n",
    "                  , export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9707d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6d224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb77ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
