{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64306a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "# import torch.nn as nn \n",
    "import time\n",
    "import math\n",
    "# import torch.nn.functional as F\n",
    "#from net import *\n",
    "#from utils import *\n",
    "#from tracker import *\n",
    "import onnx\n",
    "\n",
    "from main.paths import ROOT_PATH  # isort:skip\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import sys\n",
    "import cv2\n",
    "from loguru import logger\n",
    "\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "# import torch.nn as nn \n",
    "import time\n",
    "import math\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "from tracker import *\n",
    "from videoanalyst.config.config import cfg as root_cfg\n",
    "from videoanalyst.config.config import specify_task\n",
    "from videoanalyst.data import builder as dataloader_builder\n",
    "from videoanalyst.engine import builder as engine_builder\n",
    "from videoanalyst.model import builder as model_builder\n",
    "from videoanalyst.optim import builder as optim_builder\n",
    "from videoanalyst.utils import Timer, complete_path_wt_root_in_cfg, ensure_dir\n",
    "from videoanalyst.pipeline import builder as pipeline_builder\n",
    "from videoanalyst.engine.builder import build as tester_builder\n",
    "from videoanalyst.engine.monitor.monitor_impl.tensorboard_logger import TensorboardLogger\n",
    "from videoanalyst.config.config import cfg as root_cfg\n",
    "from videoanalyst.config.config import specify_task\n",
    "from videoanalyst.engine.builder import build as tester_builder\n",
    "from videoanalyst.model import builder as model_builder\n",
    "from videoanalyst.pipeline import builder as pipeline_builder\n",
    "from videoanalyst.utils import complete_path_wt_root_in_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb00de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.setNumThreads(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dbe5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_args_config = '/home/meysam/test-apps/STMTrack/experiments/stmtrack/test/got10k/stmtrack-effnet-got.yaml'\n",
    "exp_cfg_path = osp.realpath(parsed_args_config)\n",
    "\n",
    "root_cfg.merge_from_file(exp_cfg_path)\n",
    "\n",
    "root_cfg = complete_path_wt_root_in_cfg(root_cfg, ROOT_PATH)\n",
    "\n",
    "task, task_cfg = specify_task(root_cfg.test)\n",
    "\n",
    "task_cfg.freeze()\n",
    "\n",
    "log_dir = osp.join(task_cfg.exp_save, task_cfg.exp_name, \"logs\")\n",
    "\n",
    "ensure_dir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e9d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-18 13:51:24.723 | INFO     | __main__:<module>:15 - Load experiment configuration at: /home/meysam/test-apps/STMTrack/experiments/stmtrack/test/got10k/stmtrack-effnet-got.yaml\n",
      "2024-08-18 13:51:24.723 | INFO     | __main__:<module>:16 - Merged with root_cfg imported from videoanalyst.config.config.cfg\n",
      "2024-08-18 13:51:24.741 | INFO     | __main__:<module>:23 - Task configuration backed up at /home/meysam/test-apps/STMTrack/logs/stmtrack-effnet-got-test/got10k/logs/got10k_bak.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logger.configure(\n",
    "        handlers=[\n",
    "            dict(sink=sys.stderr, level=\"INFO\"),\n",
    "            dict(sink=osp.join(log_dir, \"train_log.txt\"),\n",
    "                 enqueue=True,\n",
    "                 serialize=True,\n",
    "                 diagnose=True,\n",
    "                 backtrace=True,\n",
    "                 level=\"INFO\")\n",
    "        ],\n",
    "        extra={\"common_to_all\": \"default\"},\n",
    "    )\n",
    "\n",
    "# backup config\n",
    "logger.info(\"Load experiment configuration at: %s\" % exp_cfg_path)\n",
    "logger.info(\n",
    "    \"Merged with root_cfg imported from videoanalyst.config.config.cfg\")\n",
    "cfg_bak_file = osp.join(log_dir, \"%s_bak.yaml\" % task_cfg.exp_name)\n",
    "\n",
    "with open(cfg_bak_file, \"w\") as f:\n",
    "    f.write(task_cfg.dump())\n",
    "\n",
    "logger.info(\"Task configuration backed up at %s\" % cfg_bak_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "858f6330",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'snapshots/stmtrack-effnet-adam-got-train-lr-mdim-8/epoch-8.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_274894/1094015511.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/test-apps/STMTrack/videoanalyst/model/builder.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(task, cfg)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         task_model = task_builder.build(task, cfg.task_model, backbone_m,\n\u001b[0m\u001b[1;32m     44\u001b[0m                                         backbone_q, neck_m, neck_q, head, losses)\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test-apps/STMTrack/videoanalyst/model/task_model/builder.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(task, cfg, backbone_m, backbone_q, neck_m, neck_q, head, loss)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mhps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_cfg_into_hps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mtask_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtask_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtask_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test-apps/STMTrack/videoanalyst/model/task_model/taskmodel_impl/stmtrack_model.py\u001b[0m in \u001b[0;36mupdate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_convs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_convs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test-apps/STMTrack/videoanalyst/model/module_base.py\u001b[0m in \u001b[0;36mupdate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyper_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pretrain_model_path\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             state_dict = torch.load(model_file,\n\u001b[0m\u001b[1;32m     56\u001b[0m                                     map_location=torch.device(\"cpu\"))\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_state_dict\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'snapshots/stmtrack-effnet-adam-got-train-lr-mdim-8/epoch-8.pkl'"
     ]
    }
   ],
   "source": [
    "model = model_builder.build(task, task_cfg.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16e6df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basemodel_Q(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Basemodel_Q, self).__init__()\n",
    "        self.backbone_q = model.basemodel_q\n",
    "        self.neck_q = model.neck_q\n",
    "    def forward(self, search_img):\n",
    "        fq = self.backbone_q(search_img)\n",
    "        fq = self.neck_q(fq)\n",
    "        return fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3c80382",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Basemodel_Q()\n",
    "ONNX_FILE_PATH = \"backbone_q.onnx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8771e69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn(1,3,200,200).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "y = net(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "985c2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(net, input, ONNX_FILE_PATH, input_names=[\"search_img\"], output_names=[\"fq\"], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fa3c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Memorize(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Memorize, self).__init__()\n",
    "        self.backbone_m = model.basemodel_m\n",
    "        self.neck_m = model.neck_m\n",
    "    def forward(self, im_crop, fg_bg_label_map):\n",
    "        fm = self.backbone_m(im_crop, fg_bg_label_map)\n",
    "        fm = self.neck_m(fm)\n",
    "        fm = fm.permute(1, 0, 2, 3).unsqueeze(0).contiguous()  # B, C, T, H, W\n",
    "        return fm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2703e332",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Memorize()#(model.basemodel_m,model.neck_m)\n",
    "\n",
    "input = torch.ones(1,3,200,200).cuda()\n",
    "fg_bg = torch.ones(1,1,200,200).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "fm = net(input,fg_bg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "425402d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 1, 25, 25])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8af6898",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_FILE_PATH = \"memorize.onnx\"\n",
    "input = torch.randn(1,3,200,200).cuda()\n",
    "fg_bg = torch.randn(1,1,200,200).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "torch.onnx.export(net, (input,fg_bg), ONNX_FILE_PATH, input_names=[\"img\",\"fg_bg_label_map\"], output_names=[\"fm\"], export_params=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b15a182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = dict(\n",
    "        total_stride=8,\n",
    "        score_size=25,\n",
    "        score_offset=-1,\n",
    "        test_lr=0.95,\n",
    "        penalty_k=0.04,\n",
    "        window_influence=0.21,\n",
    "        windowing=\"cosine\",\n",
    "        m_size=200,\n",
    "        q_size=200,\n",
    "        min_w=10,\n",
    "        min_h=10,\n",
    "        phase_memorize=\"memorize\",\n",
    "        phase_track=\"track\",\n",
    "        corr_fea_output=False,\n",
    "        num_segments=4,\n",
    "        confidence_threshold=0.6,\n",
    "        gpu_memory_threshold=-1,\n",
    "        search_area_factor=4.0,\n",
    "        visualization=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48df3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(xy_ctr, offsets):\n",
    "    offsets = offsets.permute(0, 2, 3, 1)  # (B, H, W, C), C=4\n",
    "    offsets = offsets.reshape(offsets.shape[0], -1, 4)\n",
    "    xy0 = (xy_ctr[:, :, :] - offsets[:, :, :2])\n",
    "    xy1 = (xy_ctr[:, :, :] + offsets[:, :, 2:])\n",
    "    bboxes_pred = torch.cat([xy0, xy1], 2)\n",
    "\n",
    "    return bboxes_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "633eb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self,head):\n",
    "        super(Head, self).__init__()\n",
    "        self.head = head\n",
    "        self.total_stride = 8\n",
    "        score_offset = (hps[\"q_size\"] - 1.0 - (hps[\"score_size\"] - 1) * hps[\"total_stride\"]) // 2.0\n",
    "        self.fm_ctr = get_xy_ctr_np(hps[\"score_size\"], score_offset, hps[\"total_stride\"])\n",
    "    def forward(self,fm1,fm2,fm3,fm4,fm5,fm6,fq):\n",
    "\n",
    "        fm = torch.cat([fm1,fm2,fm3,fm4,fm5,fm6],dim = 2)\n",
    "        y = self.head.memory_read(fm, fq)\n",
    "        cls_score, ctr_score, offsets, cls_feat = self.head.solve(y)\n",
    "        \n",
    "        cls_score = cls_score.permute(0, 2, 3, 1)\n",
    "        cls_score = cls_score.reshape(cls_score.shape[0], -1, 1)\n",
    "\n",
    "        ctr_score = ctr_score.permute(0, 2, 3, 1)\n",
    "        ctr_score = ctr_score.reshape(ctr_score.shape[0], -1, 1)\n",
    "\n",
    "        offsets = torch.exp(self.head.si * offsets + self.head.bi) * self.total_stride\n",
    "\n",
    "        \n",
    "        fm_ctr = self.fm_ctr.to(offsets.device)\n",
    "        bbox = get_box(fm_ctr, offsets)\n",
    "        fcos_cls_score_final = cls_score\n",
    "        fcos_ctr_score_final = ctr_score\n",
    "        fcos_bbox_final = bbox\n",
    "\n",
    "        \n",
    "        fcos_cls_prob_final = torch.sigmoid(fcos_cls_score_final)\n",
    "        fcos_ctr_prob_final = torch.sigmoid(fcos_ctr_score_final)\n",
    "        # apply centerness correction\n",
    "        fcos_score_final = fcos_cls_prob_final * fcos_ctr_prob_final\n",
    "        return fcos_score_final, fcos_bbox_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "067b5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "net = Head(model.head)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "ONNX_FILE_PATH = \"head.onnx\"\n",
    "# fm = torch.randn(1, 512, 6, 25, 25).cuda()\n",
    "fm1 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm2 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm3 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm4 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm5 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "fm6 = torch.randn(1, 20, 1, 25, 25).cuda()\n",
    "\n",
    "fq = torch.randn(1, 20, 25, 25).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b8a2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, bbox = net(fm1,fm2,fm3,fm4,fm5,fm6,fq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d393cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(net, (fm1,fm2,fm3,fm4,fm5,fm6,fq), \n",
    "                  ONNX_FILE_PATH, input_names=[\"fm1\",\"fm2\",\"fm3\",\"fm4\",\"fm5\",\"fm6\",\"fq\"], \n",
    "                  output_names=[\"score\", \"bbox\"]\n",
    "                  , export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9707d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
