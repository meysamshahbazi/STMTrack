{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7195ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import glob\n",
    "# import os.path as osp\n",
    "import torch\n",
    "import argparse\n",
    "import os.path as osp\n",
    "import sys\n",
    "import cv2\n",
    "from loguru import logger\n",
    "\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "# import torch.nn as nn \n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8197a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gt = \"/media/meysam/hdd/dataset/Dataset_UAV123/UAV123/anno/UAV123/car1_s.txt\" \n",
    "img_files_path = glob.glob(\"/media/meysam/hdd/dataset/Dataset_UAV123/UAV123/data_seq/UAV123/car1_s/*\")\n",
    "img_files_path.sort()\n",
    "frame = cv2.imread(img_files_path[0], cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file = open(path_gt)\n",
    "\n",
    "line = my_file.readline()\n",
    "line = [int(l) for l in line[:-1].split(',')]\n",
    "my_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4421ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "box = line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ac004",
   "metadata": {},
   "outputs": [],
   "source": [
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90d924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1c7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6adee11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed78af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_size = 200\n",
    "target_sz_area = box[2]*box[3]\n",
    "search_area_factor = 4.0\n",
    "search_area = search_area_factor*search_area_factor*target_sz_area;\n",
    "target_scale = np.sqrt(search_area)/q_size;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193ec64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sz = np.array([q_size, q_size])\n",
    "sample_sz = target_scale * output_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e145494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d31049",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_62009/1603994635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "pos = np.array([box[1] + box[3]/2.0, box[0] + box[2]/2.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8614f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ef449",
   "metadata": {},
   "outputs": [],
   "source": [
    "posl = pos.astype(np.int).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "posl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5befd243",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_factor = np.min(sample_sz.astype(np.float) / output_sz.astype(np.float)).item()\n",
    "df = int(max(int(resize_factor - 0.1), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8758cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87616efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = sample_sz.astype(np.float) / df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39006af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64476a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os = posl % df  # offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8526e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "posl = (posl - os) // df  # new position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "posl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "im2 = im[os[0].item()::df, os[1].item()::df, :]  # downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac56115",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.shape[0]/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5213b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "szl = np.maximum(np.round(sz), 2.0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fac26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "szl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = posl - (szl - 1) // 2\n",
    "br = posl + szl // 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fd0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl*df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76901f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "br*df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8546147",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_xyxy = np.array([tl[1], tl[0], br[1], br[0]])\n",
    "# warpAffine transform matrix\n",
    "M_13 = crop_xyxy[0]\n",
    "M_23 = crop_xyxy[1]\n",
    "M_11 = (crop_xyxy[2] - M_13) / (output_sz[0] - 1)\n",
    "M_22 = (crop_xyxy[3] - M_23) / (output_sz[1] - 1)\n",
    "mat2x3 = np.array([\n",
    "    M_11,\n",
    "    0,\n",
    "    M_13,\n",
    "    0,\n",
    "    M_22,\n",
    "    M_23,\n",
    "]).reshape(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a0b490",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_patch = cv2.warpAffine(im2, mat2x3, \n",
    "                          (output_sz[0], output_sz[1]),\n",
    "                          flags=(cv2.INTER_LINEAR | cv2.WARP_INVERSE_MAP),\n",
    "                          borderMode=cv2.BORDER_CONSTANT,\n",
    "                          borderValue=(0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d7f2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b30f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e01fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eacbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_crop_numpy(im: np.ndarray, pos: np.ndarray, sample_sz: np.ndarray, output_sz: np.ndarray = None,\n",
    "                   mode: str = 'constant', avg_chans=(0, 0, 0), max_scale_change=None):\n",
    "    \"\"\"Sample an image patch.\n",
    "\n",
    "    args:\n",
    "        im: Image\n",
    "        pos: center position of crop\n",
    "        sample_sz: size to crop\n",
    "        output_sz: size to resize to\n",
    "        mode: how to treat image borders: 'replicate' (default), 'inside' or 'inside_major'\n",
    "        max_scale_change: maximum allowed scale change when using 'inside' and 'inside_major' mode\n",
    "    \"\"\"\n",
    "\n",
    "    # if mode not in ['replicate', 'inside']:\n",
    "    #     raise ValueError('Unknown border mode \\'{}\\'.'.format(mode))\n",
    "\n",
    "    # copy and convert\n",
    "    posl = pos.astype(np.int).copy()\n",
    "\n",
    "    # Get new sample size if forced inside the image\n",
    "    \n",
    "    if mode == 'inside' or mode == 'inside_major':\n",
    "        pad_mode = 'replicate'\n",
    "        # im_sz = torch.tensor([im.shape[2], im.shape[3]], device=im.device)\n",
    "        # shrink_factor = (sample_sz.float() / im_sz)\n",
    "        im_sz = np.array([im.shape[0], im.shape[1]])\n",
    "        shrink_factor = (sample_sz.astype(np.float) / im_sz)\n",
    "        if mode == 'inside':\n",
    "            shrink_factor = shrink_factor.max()\n",
    "        elif mode == 'inside_major':\n",
    "            shrink_factor = shrink_factor.min()\n",
    "        shrink_factor.clamp_(min=1, max=max_scale_change)\n",
    "        # sample_sz = (sample_sz.float() / shrink_factor).long()\n",
    "        sample_sz = (sample_sz.astype(np.float) / shrink_factor).astype(np.int)\n",
    "\n",
    "    # Compute pre-downsampling factor\n",
    "    if output_sz is not None:\n",
    "        # resize_factor = torch.min(sample_sz.float() / output_sz.float()).item()\n",
    "        resize_factor = np.min(sample_sz.astype(np.float) / output_sz.astype(np.float)).item()\n",
    "        df = int(max(int(resize_factor - 0.1), 1))\n",
    "    else:\n",
    "        df = int(1)\n",
    "\n",
    "    # sz = sample_sz.float() / df  # new size\n",
    "    sz = sample_sz.astype(np.float) / df\n",
    "\n",
    "    # Do downsampling\n",
    "    if df > 1:\n",
    "        os = posl % df  # offset\n",
    "        posl = (posl - os) // df  # new position\n",
    "        im2 = im[os[0].item()::df, os[1].item()::df, :]  # downsample\n",
    "        # print(im2.shape)\n",
    "        # print(os)\n",
    "        # print(df)\n",
    "    else:\n",
    "        im2 = im\n",
    "\n",
    "    # compute size to crop\n",
    "    # szl = torch.max(sz.round(), torch.tensor([2.0], dtype=sz.dtype, device=sz.device)).long()\n",
    "    szl = np.maximum(np.round(sz), 2.0).astype(np.int)\n",
    "\n",
    "    # Extract top and bottom coordinates\n",
    "    tl = posl - (szl - 1) // 2\n",
    "    br = posl + szl // 2 + 1\n",
    "\n",
    "    # Shift the crop to inside\n",
    "    if mode == 'inside' or mode == 'inside_major':\n",
    "        # im2_sz = torch.LongTensor([im2.shape[2], im2.shape[3]])\n",
    "        # shift = (-tl).clamp(0) - (br - im2_sz).clamp(0)\n",
    "        im2_sz = np.array([im2.shape[0], im2.shape[1]], dtype=np.int)\n",
    "        shift = np.clip(-tl, 0) - np.clip(br - im2_sz, 0)\n",
    "        tl += shift\n",
    "        br += shift\n",
    "\n",
    "        # outside = ((-tl).clamp(0) + (br - im2_sz).clamp(0)) // 2\n",
    "        # shift = (-tl - outside) * (outside > 0).long()\n",
    "        outside = (np.clip(-tl, 0) - np.clip(br - im2_sz, 0)) // 2\n",
    "        shift = (-tl - outside) * (outside > 0).astype(np.int)\n",
    "        tl += shift\n",
    "        br += shift\n",
    "\n",
    "        # Get image patch\n",
    "        # im_patch = im2[...,tl[0].item():br[0].item(),tl[1].item():br[1].item()]\n",
    "\n",
    "    crop_xyxy = np.array([tl[1], tl[0], br[1], br[0]])\n",
    "    # warpAffine transform matrix\n",
    "    M_13 = crop_xyxy[0]\n",
    "    M_23 = crop_xyxy[1]\n",
    "    M_11 = (crop_xyxy[2] - M_13) / (output_sz[0] - 1)\n",
    "    M_22 = (crop_xyxy[3] - M_23) / (output_sz[1] - 1)\n",
    "    mat2x3 = np.array([\n",
    "        M_11,\n",
    "        0,\n",
    "        M_13,\n",
    "        0,\n",
    "        M_22,\n",
    "        M_23,\n",
    "    ]).reshape(2, 3)\n",
    "\n",
    "    # cv2.imshow(\"im2\", im2)\n",
    "    # print(\"im2 shape \", im2.shape)\n",
    "    # print(os)\n",
    "\n",
    "    im_patch = cv2.warpAffine(im2, mat2x3, \n",
    "                              (output_sz[0], output_sz[1]),\n",
    "                              flags=(cv2.INTER_LINEAR | cv2.WARP_INVERSE_MAP),\n",
    "                              borderMode=cv2.BORDER_CONSTANT,\n",
    "                              borderValue=tuple(map(int, avg_chans)))\n",
    "    \n",
    "\n",
    "    # cv2.imshow(\"im_patch\", im_patch)\n",
    "    # cv2.waitKey(0)\n",
    "    # Get image coordinates\n",
    "    patch_coord = df * np.concatenate([tl, br]).reshape(1, 4)\n",
    "    scale = output_sz / (np.array([br[1] - tl[1] + 1, br[0] - tl[0] + 1]) * df)\n",
    "    return im_patch, patch_coord, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c8e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
